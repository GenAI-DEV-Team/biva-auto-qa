# ‚ùì FAQ - C√¢u h·ªèi th∆∞·ªùng g·∫∑p

## üìã M·ª•c l·ª•c
1. [C√†i ƒë·∫∑t & Setup](#c√†i-ƒë·∫∑t--setup)
2. [S·ª≠ d·ª•ng h·ªá th·ªëng](#s·ª≠-d·ª•ng-h·ªá-th·ªëng)
3. [API & Integration](#api--integration)
4. [Performance & Scale](#performance--scale)
5. [Troubleshooting](#troubleshooting)

---

## C√†i ƒë·∫∑t & Setup

### **Q: L√†m th·∫ø n√†o ƒë·ªÉ c√†i ƒë·∫∑t h·ªá th·ªëng?**
**A:** H·ªá th·ªëng c√≥ th·ªÉ c√†i ƒë·∫∑t theo 2 c√°ch:

**Docker (Khuy·∫øn ngh·ªã):**
```bash
git clone <repo>
cd biva-auto-qa
docker-compose up -d
```

**Development:**
- Backend: Python venv + pip install
- Frontend: npm install + npm run dev

Xem chi ti·∫øt t·∫°i [INSTALLATION.md](INSTALLATION.md)

### **Q: C·∫ßn c·∫•u h√¨nh g√¨ sau khi c√†i ƒë·∫∑t?**
**A:** C·∫ßn c·∫•u h√¨nh:
1. **OpenAI API Key** trong `backend/.env`
2. **Database credentials** (m·∫∑c ƒë·ªãnh: autoqa/autoqa)
3. **Redis URL** (m·∫∑c ƒë·ªãnh: localhost:6378)
4. **Google Sheets** (optional)

### **Q: H·ªá th·ªëng y√™u c·∫ßu t√†i nguy√™n g√¨?**
**A:** Minimum requirements:
- RAM: 4GB
- CPU: 2 cores
- Storage: 10GB
- OS: Linux/macOS/Windows (WSL2)

### **Q: C√≥ th·ªÉ ch·∫°y tr√™n cloud kh√¥ng?**
**A:** C√≥! H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ch·∫°y tr√™n:
- AWS ECS/Fargate
- Google Cloud Run
- Azure Container Instances
- DigitalOcean App Platform
- Heroku (v·ªõi m·ªôt s·ªë ƒëi·ªÅu ch·ªânh)

---

## S·ª≠ d·ª•ng h·ªá th·ªëng

### **Q: L√†m th·∫ø n√†o ƒë·ªÉ t·∫°o bot m·ªõi?**
**A:**
1. V√†o tab "Bots"
2. Nh·∫≠p "Legacy Bot Index" (s·ªë ID c·ªßa bot c≈©)
3. Click "Create Bot"
4. H·ªá th·ªëng t·ª± ƒë·ªông t·∫°o bot v·ªõi knowledge base

### **Q: QA Engine ƒë√°nh gi√° theo ti√™u ch√≠ g√¨?**
**A:** H·ªá th·ªëng ƒë√°nh gi√° theo c√°c ti√™u ch√≠:
- **Overall Score**: ƒêi·ªÉm t·ªïng th·ªÉ
- **Relevance**: ƒê·ªô li√™n quan
- **Accuracy**: ƒê·ªô ch√≠nh x√°c
- **Helpfulness**: T√≠nh h·ªØu √≠ch
- **Safety**: ƒê·ªô an to√†n

### **Q: C√≥ th·ªÉ ch·∫°y QA cho nhi·ªÅu conversations c√πng l√∫c kh√¥ng?**
**A:** C√≥! H·ªá th·ªëng h·ªó tr·ª£:
- **Single QA**: 1 conversation
- **Bulk QA**: L√™n ƒë·∫øn 20 conversations c√πng l√∫c
- **Auto QA**: T·ª± ƒë·ªông ch·ªçn conversations m·ªõi nh·∫•t

### **Q: UI c√≥ t·ª± ƒë·ªông c·∫≠p nh·∫≠t kh√¥ng?**
**A:** C√≥! H·ªá th·ªëng c√≥:
- **Auto-refresh**: M·ªói 30-60s
- **Real-time updates**: Khi QA ho√†n th√†nh
- **Visual indicators**: Hi·ªÉn th·ªã tr·∫°ng th√°i refresh

### **Q: C√≥ th·ªÉ export k·∫øt qu·∫£ ra ƒë√¢u?**
**A:** H·ªó tr·ª£ export ra:
- **Google Sheets**: T·ª± ƒë·ªông sync
- **CSV/Excel**: Download tr·ª±c ti·∫øp
- **API**: JSON endpoints

---

## API & Integration

### **Q: API c√≥ authentication kh√¥ng?**
**A:** Hi·ªán t·∫°i API kh√¥ng y√™u c·∫ßu auth cho development, nh∆∞ng c√≥ th·ªÉ th√™m JWT authentication khi c·∫ßn.

### **Q: Rate limiting nh∆∞ th·∫ø n√†o?**
**A:** H·ªá th·ªëng c√≥ rate limiting:
- QA runs: 3 concurrent requests
- API calls: 100 requests/minute
- Database connections: 10-20 pool

### **Q: C√≥ webhook/notification kh√¥ng?**
**A:** Hi·ªán t·∫°i ch∆∞a c√≥ webhook, nh∆∞ng c√≥ th·ªÉ t√≠ch h·ª£p:
- Slack notifications
- Email alerts
- WebSocket real-time updates

### **Q: Database schema c√≥ th·ªÉ customize kh√¥ng?**
**A:** C√≥! C√≥ th·ªÉ:
- Th√™m fields m·ªõi v√†o models
- T·∫°o custom evaluation metrics
- Extend conversation data structure

---

## Performance & Scale

### **Q: H·ªá th·ªëng x·ª≠ l√Ω ƒë∆∞·ª£c bao nhi√™u conversations?**
**A:** T√πy thu·ªôc v√†o infrastructure:
- **Small**: 1K-10K conversations
- **Medium**: 10K-100K conversations
- **Large**: 100K+ conversations (v·ªõi optimization)

### **Q: QA processing time nh∆∞ th·∫ø n√†o?**
**A:** Th·ªùi gian x·ª≠ l√Ω:
- **Single QA**: 5-15 seconds
- **Bulk QA (20 conv)**: 30-60 seconds
- **Heavy load**: C√≥ th·ªÉ l√™n ƒë·∫øn 2-3 minutes

### **Q: C√≥ th·ªÉ scale horizontally kh√¥ng?**
**A:** C√≥! C√≥ th·ªÉ scale:
- **Load balancer** cho multiple backend instances
- **Redis cluster** cho caching
- **Read replicas** cho database
- **CDN** cho static assets

### **Q: Memory usage nh∆∞ th·∫ø n√†o?**
**A:** Memory consumption:
- **Base system**: ~200MB
- **Per conversation**: ~1-5MB
- **Cache**: T√πy thu·ªôc v√†o data size

---

## Troubleshooting

### **Q: API tr·∫£ v·ªÅ empty array?**
**A:** Th·ª≠ c√°c c√°ch sau:
```bash
# 1. X√≥a cache
curl -X DELETE http://localhost:13886/api/v1/bots/cache

# 2. Restart Redis
docker-compose restart redis

# 3. Check database
docker-compose exec postgres psql -U autoqa -d autoqa -c "SELECT COUNT(*) FROM bots;"
```

### **Q: OpenAI API quota exceeded?**
**A:** C√°c gi·∫£i ph√°p:
1. **Ki·ªÉm tra quota**: T·∫°i OpenAI dashboard
2. **Gi·∫£m model size**: D√πng GPT-3.5 thay v√¨ GPT-4
3. **Rate limiting**: TƒÉng interval gi·ªØa requests
4. **Batch processing**: X·ª≠ l√Ω theo batches nh·ªè h∆°n

### **Q: Database connection error?**
**A:**
```bash
# 1. Restart database
docker-compose restart postgres

# 2. Check logs
docker-compose logs postgres

# 3. Reset database
docker-compose down -v
docker volume rm biva-auto-qa_pgdata
docker-compose up -d postgres
```

### **Q: Frontend kh√¥ng load ƒë∆∞·ª£c?**
**A:**
```bash
# 1. Clear cache
cd qa-dialog-compass
rm -rf node_modules package-lock.json
npm cache clean --force

# 2. Reinstall
npm install
npm run dev

# 3. Check port conflicts
lsof -ti:3000 | xargs kill -9
```

### **Q: Slow API responses?**
**A:** T·ªëi ∆∞u performance:
```bash
# 1. Check database indexes
docker-compose exec postgres psql -U autoqa -d autoqa -c "\d conversations"

# 2. Monitor Redis
docker-compose exec redis redis-cli info memory

# 3. Optimize config
# TƒÉng DB_POOL_SIZE=20
# TƒÉng REDIS_MAX_CONNECTIONS=100
```

### **Q: High CPU usage?**
**A:** Gi·∫£m load:
```bash
# 1. Gi·∫£m concurrent QA runs
# 2. TƒÉng polling intervals
# 3. Use smaller AI models
# 4. Add more caching
```

### **Q: CORS errors?**
**A:** C·∫•u h√¨nh CORS trong backend:
```env
CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:8080
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=*
CORS_ALLOW_HEADERS=*
```

### **Q: Memory leaks?**
**A:** Monitoring v√† cleanup:
```bash
# 1. Monitor memory usage
docker stats

# 2. Restart containers periodically
docker-compose restart

# 3. Check for memory leaks in logs
docker-compose logs -f backend | grep -i "memory\|leak"
```

---

## Support & Community

### **Q: L√†m th·∫ø n√†o ƒë·ªÉ contribute?**
**A:**
1. Fork repository
2. T·∫°o feature branch
3. Implement changes
4. T·∫°o Pull Request
5. Follow coding standards

### **Q: C√≥ community/discord kh√¥ng?**
**A:** Hi·ªán t·∫°i ch∆∞a c√≥ community ch√≠nh th·ª©c, nh∆∞ng c√≥ th·ªÉ:
- T·∫°o GitHub Discussions
- T·∫°o Discord/Slack workspace
- T·∫°o Stack Overflow tag

### **Q: C√≥ training/documentation kh√¥ng?**
**A:** C√≥ ƒë·∫ßy ƒë·ªß documentation:
- [README.md](README.md) - T·ªïng quan
- [INSTALLATION.md](INSTALLATION.md) - C√†i ƒë·∫∑t chi ti·∫øt
- [QUICKSTART.md](QUICKSTART.md) - B·∫Øt ƒë·∫ßu nhanh
- API Docs t·∫°i `/docs`

### **Q: H·ªó tr·ª£ enterprise/commercial?**
**A:** C√≥ th·ªÉ h·ªó tr·ª£:
- Custom features
- On-premise deployment
- Enterprise security
- SLA & support contracts
- Training & consulting

---

**C√¢u h·ªèi kh√°c? T·∫°o issue tr√™n GitHub! üöÄ**
